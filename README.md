# Speech Emotion Recognition

## Overview

This project implements an advanced Neural Network architecture for precise Speech Emotion Recognition. The model combines Convolutional Neural Network (CNN) and Long Short-Term Memory (LSTM) layers to effectively capture and analyze audio signals for emotion classification.

## Key Features

- **Neural Network Architecture:** The model utilizes a combination of CNN and LSTM layers for robust emotion recognition.

- **MFCC Feature Extraction:** Mel-Frequency Cepstral Coefficients (MFCC) are extracted to capture essential audio signal attributes.

- **CNN for Feature Recognition:** Convolutional Neural Network is employed for initial feature recognition.

- **LSTM for Temporal Dependencies:** Long Short-Term Memory is seamlessly integrated to capture temporal dependencies in the audio signals.

## Algorithms & Tools

- **Deep Learning Framework:** Keras
- **Feature Extraction:** MFCC (Mel-Frequency Cepstral Coefficients)
- **Neural Network Layers:** CNN, LSTM
- **Audio Processing:** Librosa
- **Visualization:** Seaborn, Matplotlib
- **Programming Language:** Python
